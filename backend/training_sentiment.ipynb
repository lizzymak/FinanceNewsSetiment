{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "571d32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7973cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                               text\n",
      "0   neutral  According to Gran , the company has no plans t...\n",
      "1   neutral  Technopolis plans to develop in stages an area...\n",
      "2  negative  The international electronic industry company ...\n",
      "3  positive  With the new production plant the company woul...\n",
      "4  positive  According to the company 's updated strategy f...\n",
      "Index(['label', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load data set\n",
    "df = pd.read_csv(\"news.csv\", encoding='latin-1', header=None) \n",
    "df.columns = ['label', 'text']\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfb208ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label classes: ['negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "# clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower() # convert string to lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # remove links\n",
    "    text = re.sub(r'\\@w+|\\#','', text)  # remove mentions and hashtags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # remove numbers and punctuation\n",
    "    return text\n",
    "df['text'] = df['text'].astype(str).apply(clean_text) # updates text column to string and cleans\n",
    "\n",
    "# encode labels\n",
    "encoder = LabelEncoder()\n",
    "df['label'] = encoder.fit_transform(df['label'])  \n",
    "\n",
    "print(\"Label classes:\", encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aea762b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/tests split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "# here were training it so it can predict what label each text goes under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dfd2d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4039\n"
     ]
    }
   ],
   "source": [
    "# create data set class\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# splits text at any whitespace\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "# goes through all of the text and yeilds the tokens\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "def build_vocab(texts, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(tokenizer(text))\n",
    "    # start indices at 2 so we can reserve 0 for PAD and 1 for UNK\n",
    "    vocab = {word: i+2 for i, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
    "    vocab[\"<pad>\"] = 0\n",
    "    vocab[\"<unk>\"] = 1\n",
    "    return vocab\n",
    "\n",
    "vocab_dict = build_vocab(train_texts, min_freq=2)  \n",
    "print(\"Vocab size:\", len(vocab_dict))\n",
    "\n",
    "def numericalize(text, vocab):\n",
    "    tokens = tokenizer(text)  # split into words\n",
    "    return [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8159b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 122\n",
      "Test batches: 31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "\n",
    "    # number of samples in dataset\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    # call when we want only one sample\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        tokens = torch.tensor(numericalize(text, self.vocab), dtype=torch.long) #self.vocab is for mapping words to numbers\n",
    "        return tokens, torch.tensor(label, dtype=torch.long) #returns tokens and labels\n",
    "    \n",
    "# make data into dataset object\n",
    "train_dataset = NewsDataset(train_texts, train_labels, vocab_dict)\n",
    "test_dataset = NewsDataset(test_texts, test_labels, vocab_dict)\n",
    "\n",
    "def collate_batch(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts = pad_sequence(texts, batch_first=True, padding_value=0) #makes all lists same length by adding zeros at end\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return texts, labels\n",
    "\n",
    "# train 32 healines per batch\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_batch) # reshuffle every epoch\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_batch)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader))\n",
    "print(\"Test batches:\", len(test_loader))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
